{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8226ec5b-c82f-46cb-bb25-6b1f8d8d7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit\n",
    "from pymer4.models import Lmer\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf55f5d-9b13-4830-aa1e-2228f09dd886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生物量的季节性变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20edce3d-a01c-460b-8e41-510ba6bc0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_data = pd.read_csv('./Site_igbp.csv', encoding='latin-1')\n",
    "site_IGBP = type_data['igbp'].values\n",
    "site_lat = type_data['lat'].values\n",
    "site_ID =  type_data['site'].values\n",
    "\n",
    "path = 'D:Data/Fluxnet/All_hourly_data/'\n",
    "\n",
    "site = ['site']\n",
    "igbp = ['igbp']\n",
    "year_list = ['year']\n",
    "RECO = [['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9'], ['10'], ['11'], ['12']]\n",
    "\n",
    "\n",
    "for csv_file in os.listdir(path):\n",
    "    if site_lat[site_ID==csv_file[4:10]][0] < 0:\n",
    "        data = pd.read_csv(path+csv_file)\n",
    "        year = (data['TIMESTAMP_START']/100000000).astype(int)\n",
    "        month = np.round(data['TIMESTAMP_START']/1000000).astype(int)%100\n",
    "        hour = (data['TIMESTAMP_START']%10000).astype(int)\n",
    "        unique_values = np.unique(year)\n",
    "\n",
    "        for i in range(len(unique_values)):\n",
    "            Ti_0 = data['TA_F_MDS'].values\n",
    "            RECOi_0 = data['RECO_NT_VUT_REF'].values\n",
    "            T_QCi_0 = data['TA_F_MDS_QC'].values\n",
    "        \n",
    "            Reco_months = []\n",
    "            \n",
    "            Ti_1 = Ti_0[(Ti_0 !=-9999)]\n",
    "            T_mean = np.mean(Ti_1)\n",
    "            \n",
    "            for j in range(12):\n",
    "                if T_mean < 10:\n",
    "                    RECOj = RECOi_0[(Ti_0!=-9999) & (RECOi_0!=-9999) & (RECOi_0>0.001) & (T_QCi_0==0) & (year==unique_values[i]) & (month==j+1) & (Ti_0>=9) & (Ti_0<11) & ((hour>=1900) | (hour<=700))]\n",
    "                elif T_mean >= 10 and T_mean < 15:\n",
    "                    RECOj = RECOi_0[(Ti_0!=-9999) & (RECOi_0!=-9999) & (RECOi_0>0.001) & (T_QCi_0==0) & (year==unique_values[i]) & (month==j+1) & (Ti_0>=14) & (Ti_0<16) & ((hour>=1900) | (hour<=700))]\n",
    "                elif T_mean >= 15 and T_mean < 20:\n",
    "                    RECOj = RECOi_0[(Ti_0!=-9999) & (RECOi_0!=-9999) & (RECOi_0>0.001) & (T_QCi_0==0) & (year==unique_values[i]) & (month==j+1) & (Ti_0>=19) & (Ti_0<21) & ((hour>=1900) | (hour<=700))]\n",
    "                elif T_mean >= 20:\n",
    "                    RECOj = RECOi_0[(Ti_0!=-9999) & (RECOi_0!=-9999) & (RECOi_0>0.001) & (T_QCi_0==0) & (year==unique_values[i]) & (month==j+1) & (Ti_0>=24) & (Ti_0<26) & ((hour>=1900) | (hour<=700))]\n",
    "                if len(RECOj) >10:\n",
    "                    RECO[j].append(np.mean(RECOj))\n",
    "                else:\n",
    "                    RECO[j].append(np.nan)\n",
    "            \n",
    "            site.append(csv_file[4:10])\n",
    "            igbp.append(site_IGBP[site_ID==csv_file[4:10]][0])\n",
    "            year_list.append(unique_values[i])\n",
    "            \n",
    "        result = np.array([site, igbp, year_list, RECO[0], RECO[1], RECO[2], RECO[3], RECO[4], RECO[5], RECO[6], RECO[7], RECO[8], RECO[9], RECO[10], RECO[11]])\n",
    "        result_pd = pd.DataFrame(result.T)\n",
    "        save_path = './Result1_intro/RECO_seasonal_change_south_nighttime.csv'\n",
    "        result_pd.to_csv(save_path, index= 'a', header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04999a94-6c7c-40bc-b44e-dfc1e8234f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Result1_intro/RECO_seasonal_change_south_nighttime.csv')\n",
    "site = ['site']\n",
    "igbp = ['igbp']\n",
    "year_list = ['year']\n",
    "RECO = [['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9'], ['10'], ['11'], ['12']]\n",
    "m,n = data.shape\n",
    "\n",
    "for i in range(m):\n",
    "    RECO_all = []\n",
    "    for j in range(12):\n",
    "        RECO_all.append(data[str(j+1)][i])\n",
    "    if np.sum(np.isnan(RECO_all)) <= 5:\n",
    "        for j in range(12):\n",
    "            RECO[j].append( RECO_all[j]/np.nanmean(RECO_all) )\n",
    "        site.append(data['site'][i])\n",
    "        igbp.append(data['igbp'][i])\n",
    "        year_list.append(data['year'][i])\n",
    "    result = np.array([site, igbp, year_list, RECO[0], RECO[1], RECO[2], RECO[3], RECO[4], RECO[5], RECO[6], RECO[7], RECO[8], RECO[9], RECO[10], RECO[11]])\n",
    "    result_pd = pd.DataFrame(result.T)\n",
    "    save_path = './Result1_intro/RECO_seasonal_change_normalized_south_nighttime.csv'\n",
    "    result_pd.to_csv(save_path, index= 'a', header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4db2f0-0109-4726-8ed0-bd4beb26e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#呼吸的月平均变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122439ce-16c1-431e-a23a-092e0781d049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "type_data = pd.read_csv('./Site_igbp.csv', encoding='latin-1')\n",
    "site_IGBP = type_data['igbp'].values\n",
    "site_lat = type_data['lat'].values\n",
    "site_ID =  type_data['site'].values\n",
    "\n",
    "path = 'D:Data/Fluxnet/All_hourly_data/'\n",
    "\n",
    "site = ['site']\n",
    "igbp = ['igbp']\n",
    "year_list = ['year']\n",
    "RECO = [['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9'], ['10'], ['11'], ['12']]\n",
    "\n",
    "\n",
    "for csv_file in os.listdir(path):\n",
    "    if site_lat[site_ID==csv_file[4:10]][0] > -50:\n",
    "        data = pd.read_csv(path+csv_file)\n",
    "        year = (data['TIMESTAMP_START']/100000000).astype(int)\n",
    "        month = np.round(data['TIMESTAMP_START']/1000000).astype(int)%100\n",
    "        hour = (data['TIMESTAMP_START']%10000).astype(int)\n",
    "        unique_values = np.unique(year)\n",
    "\n",
    "        for i in range(len(unique_values)):\n",
    "            Ti_0 = data['TA_F_MDS'].values\n",
    "            RECOi_0 = data['RECO_NT_VUT_REF'].values\n",
    "            T_QCi_0 = data['TA_F_MDS_QC'].values\n",
    "        \n",
    "            Reco_months = []\n",
    "            \n",
    "            Ti_1 = Ti_0[(Ti_0 !=-9999)]\n",
    "            T_mean = np.mean(Ti_1)\n",
    "            \n",
    "            for j in range(12):\n",
    "                RECOj = RECOi_0[(Ti_0!=-9999) & (RECOi_0!=-9999) & (RECOi_0>0.001) & (T_QCi_0==0) & (year==unique_values[i]) & (month==j+1) & ((hour>=1900) | (hour<=700))]\n",
    "                if len(RECOj) >100:\n",
    "                    RECO[j].append(np.mean(RECOj))\n",
    "                else:\n",
    "                    RECO[j].append(np.nan)\n",
    "            \n",
    "            site.append(csv_file[4:10])\n",
    "            igbp.append(site_IGBP[site_ID==csv_file[4:10]][0])\n",
    "            year_list.append(unique_values[i])\n",
    "            \n",
    "        result = np.array([site, igbp, year_list, RECO[0], RECO[1], RECO[2], RECO[3], RECO[4], RECO[5], RECO[6], RECO[7], RECO[8], RECO[9], RECO[10], RECO[11]])\n",
    "        result_pd = pd.DataFrame(result.T)\n",
    "        save_path = './Result1_intro/RECO_seasonal_change_monthly_mean_north_nighttime.csv'\n",
    "        result_pd.to_csv(save_path, index= 'a', header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca2327d-8408-48ae-a18e-264603e9e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './Result1_intro/RECO_seasonal_change_monthly_mean_south_nighttime.csv'\n",
    "path2 = './Result1_intro/RECO_seasonal_change_south_nighttime.csv'\n",
    "\n",
    "path3 = './Site_igbp.csv'\n",
    "path4 = './Site_climate.csv'\n",
    "\n",
    "data1 = pd.read_csv(path1)\n",
    "data2 = pd.read_csv(path2)\n",
    "\n",
    "data3 = pd.read_csv(path3)\n",
    "data4 = pd.read_csv(path4)\n",
    "\n",
    "m,n = data1.shape\n",
    "\n",
    "site = ['site']\n",
    "igbp = ['igbp']\n",
    "climate = ['climate']\n",
    "Delt_R_ref = ['delt_mean']\n",
    "Delt_R_mean = ['delt_ref']\n",
    "\n",
    "for i in range(m):\n",
    "    R_1 = []\n",
    "    R_2 = []\n",
    "    for j in range(12):\n",
    "        if np.isnan(data1[str(j+1)][i]) != 1 and np.isnan(data2[str(j+1)][i]) != 1:            \n",
    "            R_1.append(data1[str(j+1)][i])\n",
    "            R_2.append(data2[str(j+1)][i])\n",
    "\n",
    "    if len(R_1)>=5 and len(np.unique(R_1))>=5 and len(np.unique(R_2))>=5# and data1['site'][i] in data4['site'].values:\n",
    "        site.append(data1['site'][i])\n",
    "        igbp.append(data3['igbp'].values[(data3['site'].values==data1['site'][i])][0])\n",
    "        climate.append(data3['igbp'].values[(data4['site'].values==data1['site'][i])][0])\n",
    "        Delt_R_ref.append(np.max(R_1)-np.min(R_1))\n",
    "        Delt_R_mean.append(np.max(R_2)-np.min(R_2))\n",
    "result = np.array([site, igbp, Delt_R_ref, Delt_R_mean])\n",
    "result_pd = pd.DataFrame(result.T)\n",
    "save_path = './Seasonal_variation_igbp_south.csv'\n",
    "result_pd.to_csv(save_path, index= 'a', header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc5b32-6856-4ced-b26f-68ae62a0b664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b647a-843e-4d54-a47b-1e15627b85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生物量和温度的耦合对Q10的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e0a91b-07e6-40e1-8f77-bd23c8a9f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_data = pd.read_csv('./Site_igbp.csv', encoding='latin-1')\n",
    "site_IGBP = type_data['igbp'].values\n",
    "site_lat = type_data['lat'].values\n",
    "site_ID =  type_data['site'].values\n",
    "\n",
    "path = 'D:Data/Fluxnet/All_hourly_data/'\n",
    "\n",
    "site = ['site']\n",
    "igbp = ['igbp']\n",
    "year_list = ['year']\n",
    "Q10 = ['Q10']\n",
    "SE = ['SE']\n",
    "p = ['pvalue']\n",
    "cor = ['cor']\n",
    "\n",
    "days = 10\n",
    "\n",
    "for csv_file in os.listdir(path):\n",
    "    if csv_file[0] == 'F': \n",
    "        if csv_file[31:33] =='HH':\n",
    "            hours = 48\n",
    "        else:\n",
    "            hours = 24\n",
    "    else:\n",
    "        if csv_file[27:29] =='HH':\n",
    "            hours = 48\n",
    "        else:\n",
    "            hours = 24\n",
    "\n",
    "    data = pd.read_csv(path+csv_file)\n",
    "    year = (data['TIMESTAMP_START']/100000000).astype(int)\n",
    "    month = np.round(data['TIMESTAMP_START']/1000000).astype(int)%100\n",
    "    hour = (data['TIMESTAMP_START']%10000).astype(int)\n",
    "    unique_values = np.unique(year)\n",
    "    \n",
    "    for i in range(len(unique_values)):\n",
    "        Ti_0 = data['TA_F_MDS'].values\n",
    "        RECOi_0 = data['RECO_NT_VUT_REF'].values\n",
    "        T_QCi_0 = data['TA_F_MDS_QC'].values\n",
    "        Ti_1 = Ti_0[(Ti_0!=-9999) & (RECOi_0!=-9999) & (RECOi_0>0.001) & (T_QCi_0==0) & (year==unique_values[i]) & ((hour>=1900) | (hour<=700))]                        \n",
    "        RECOi_1 = RECOi_0[(Ti_0!=-9999)& (RECOi_0!=-9999) & (RECOi_0>0.001) & (T_QCi_0==0) & (year==unique_values[i]) & ((hour>=1900) | (hour<=700))]\n",
    "        Normal_Ti_1 = (Ti_1-10)/10\n",
    "        ln_RECOi_1 = np.log(RECOi_1)\n",
    "        \n",
    "\n",
    "        #计算温度和生物量之间的耦合度\n",
    "        Ti = Ti_0[(year==unique_values[i])]   \n",
    "        houri = hour[(year==unique_values[i])]\n",
    "        T_QCi = T_QCi_0[(year==unique_values[i])]\n",
    "        RECOi = RECOi_0[(year==unique_values[i])]\n",
    "        m = len(Ti)\n",
    "        \n",
    "        Reco_months = []\n",
    "        T_months = []\n",
    "        T_median = np.median(Ti_1)\n",
    "        \n",
    "        for j in range(int(m/hours/days)-1):\n",
    "            Tj = Ti[i*days*hours:(j+1)*days*hours]\n",
    "            T_QCj = T_QCi[i*days*hours:(j+1)*days*hours]\n",
    "            RECOj = RECOi[i*days*hours:(j+1)*days*hours]\n",
    "            hourj = houri[i*days*hours:(j+1)*days*hours]\n",
    "            \n",
    "            Tj_1 = Tj[(Tj!=-9999) & (RECOj!=-9999) & (RECOj>0.001) & (T_QCj==0) & ((hourj>=1900) | (hourj<=700))]\n",
    "            RECOj_1 = RECOj[(Tj!=-9999) & (RECOj!=-9999) & (RECOj>0.001) & (T_QCj==0) & (Tj >= T_median-1) & (Tj < T_median+1) & ((hourj>=1900) | (hourj<=700))]\n",
    "\n",
    "            if len(RECOj_1) >10 and len(Tj_1) >50:\n",
    "                T_months.append(np.mean(Tj_1))\n",
    "                Reco_months.append(np.mean(RECOj_1))\n",
    "        \n",
    "        if len(Reco_months) >=10:\n",
    "            if hours ==48:\n",
    "                t = 7500\n",
    "            else:\n",
    "                t = 3750\n",
    "            if len(Normal_Ti_1) > t:\n",
    "                y = ln_RECOi_1\n",
    "                X = sm.add_constant(Normal_Ti_1)\n",
    "                model = sm.OLS(y, X)\n",
    "                results = model.fit()\n",
    "                slope = results.params[1]\n",
    "                slope_pvalue = results.pvalues[1]\n",
    "                slope_standard_error = results.bse[1]\n",
    "                \n",
    "                site.append(csv_file[4:10])\n",
    "                igbp.append(site_IGBP[site_ID==csv_file[4:10]][0])\n",
    "                year_list.append(unique_values[i])\n",
    "                Q10.append(np.exp(slope))\n",
    "                SE.append(np.exp(slope+slope_standard_error)-np.exp(slope))\n",
    "                p.append(slope_pvalue)\n",
    "                cor.append(spearmanr(T_months, Reco_months)[0])\n",
    "    \n",
    "    result = np.array([site, igbp, year_list, Q10, SE, p, cor])\n",
    "    result_pd = pd.DataFrame(result.T)\n",
    "    save_path = './Q10_site_year_nighttime.csv'\n",
    "    result_pd.to_csv(save_path, index= 'a', header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5287219a-9c3b-4757-8b18-068fb3a54d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9843af-d80f-427a-b6c2-fa5e7c07b1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e80ee5d-3a50-4b17-ac8d-7a2272d6ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:Data/Fluxnet/All_hourly_data/'\n",
    "\n",
    "site = ['site']\n",
    "year_list = ['year']\n",
    "T_mean = ['Tm']\n",
    "\n",
    "\n",
    "for csv_file in os.listdir(path):\n",
    "\n",
    "    data = pd.read_csv(path+csv_file)\n",
    "    year = (data['TIMESTAMP_START']/100000000).astype(int)\n",
    "    month = np.round(data['TIMESTAMP_START']/1000000).astype(int)%100\n",
    "    unique_values = np.unique(year)\n",
    "\n",
    "    for i in range(len(unique_values)):\n",
    "        \n",
    "        Ti = data['TA_F_MDS'].values[(year==unique_values[i])]\n",
    "        T_QCi = data['TA_F_MDS_QC'].values[(year==unique_values[i])]\n",
    "        \n",
    "        Ti_1 = Ti[(Ti!=-9999) & (T_QCi == 0)]\n",
    "        if len(Ti_1)>0.9*len(Ti):\n",
    "            site.append(csv_file[4:10])\n",
    "            year_list.append(unique_values[i])\n",
    "            T_mean.append(np.mean(Ti_1))\n",
    "        result = np.array([site, year_list, T_mean])\n",
    "        result_pd = pd.DataFrame(result.T)\n",
    "        save_path = './Site_mean_T.csv'\n",
    "        result_pd.to_csv(save_path, index= 'a', header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f3b62-7654-4e0d-acea-6ab6d0501207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b70087-7405-4dc3-ac61-c62d7381ac6b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "path1 = './Q10_site_year_nighttime.csv'\n",
    "path2 = './Site_climate.csv'\n",
    "\n",
    "data1 = pd.read_csv(path1)\n",
    "data2 = pd.read_csv(path2)\n",
    "\n",
    "site = ['site']\n",
    "climate = ['climate']\n",
    "cor = ['cor']\n",
    "\n",
    "m,n = data1.shape\n",
    "\n",
    "for i in range(m):\n",
    "    if data1['site'][i] in data2['site'].values:\n",
    "        print(1)\n",
    "        site.append(data1['site'][i])\n",
    "        climate.append( data2['climate'].values[(data2['site'] == data1['site'][i])][0][0] )\n",
    "        cor.append(data1['cor'][i])\n",
    "        \n",
    "result = np.array([site, climate, cor])\n",
    "result_pd = pd.DataFrame(result.T)\n",
    "save_path = './Cor_climate.csv'\n",
    "result_pd.to_csv(save_path, index= 'a', header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d35c3-b813-44cf-a44a-6d480a947ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496c7d8d-bd10-4696-bad0-60b284cf576b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
